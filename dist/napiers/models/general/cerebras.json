
{
  "name": "cerebras",
  "description": "",
  "default": {
    "params": [
      { "key": "max_tokens", "defaultValue": 1024, "minValue": 1, "maxValue": 128000 },
      { "key": "temperature", "defaultValue": 0.7, "minValue": 0, "maxValue": 2 },
      { "key": "top_p", "defaultValue": 1, "minValue": 0, "maxValue": 1 },
      { "key": "stop", "defaultValue": null, "type": "array-of-strings", "skipValues": [null, []] },
      { "key": "stream", "defaultValue": true, "type": "boolean" }
    ],
    "messages": { "options": ["system", "user", "assistant"] },
    "type": { "primary": "chat", "supported": [] }
  },

  "llama-4-scout-17b-16e-instruct": {
    "params": [{ "key": "max_tokens", "maxValue": 32768 }],
    "type": { "primary": "chat", "supported": ["tools"] }
  },
  "llama-4-maverick-17b-128e-instruct": {
    "params": [
      { "key": "max_tokens", "maxValue": 32768 },
      { "key": "temperature", "defaultValue": 0.6 },
      { "key": "top_p", "defaultValue": 0.9 }
    ],
    "type": { "primary": "chat", "supported": ["tools"] }
  },
  "llama3.1-8b": {
    "params": [{ "key": "max_tokens", "maxValue": 32768 }],
    "type": { "primary": "chat", "supported": ["tools"] }
  },
  "llama-3.3-70b": {
    "params": [{ "key": "max_tokens", "maxValue": 32768 }],
    "type": { "primary": "chat", "supported": ["tools"] }
  },
  "qwen-3-32b": {
    "params": [
      { "key": "max_tokens", "maxValue": 32768 },
      { "key": "temperature", "defaultValue": 0.6 },
      { "key": "top_p", "defaultValue": 0.95 }
    ],
    "type": { "primary": "chat", "supported": ["tools"] }
  },
  "qwen-3-235b-a22b-instruct-2507": {
    "params": [{ "key": "max_tokens", "maxValue": 32768 }],
    "type": { "primary": "chat", "supported": ["tools"] }
  },
  "qwen-3-235b-a22b-thinking-2507": {
    "params": [{ "key": "max_tokens", "maxValue": 32768 }],
    "type": { "primary": "chat", "supported": ["tools"] }
  },
  "qwen-3-coder-480b": {
    "params": [
      { "key": "max_tokens", "maxValue": 32768 },
      { "key": "temperature", "defaultValue": 0.7 },
      { "key": "top_p", "defaultValue": 0.8 }
    ],
    "type": { "primary": "chat", "supported": ["tools"] }
  },
  "gpt-oss-120b": {
    "params": [
      { "key": "max_tokens", "maxValue": 32768 }
    ],
    "type": { "primary": "chat" },
    "removeParams": ["stream"]
  },
  "llama3.1-70b": {
    "type": {
      "primary": "chat"
    }
  },
  "zai-glm-4.6": {
    "type": {
      "primary": "chat"
    }
  }
}